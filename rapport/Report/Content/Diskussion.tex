\section{Diskussion}
\label{DIS}
For at se på mulighederne at kode til en \textit{GPU} igennem sproget C\# , som er det sprog \textit{Corecalc} er skrevet i, er der blevet lavet nogle forskellige teste, der gav nogle interessante resultater. Det kan ses på \textit{C++ AMP} og \textit{CUDA} i tabellen \ref{fig:samletC++} at \textit{C++ AMP} virker til at være meget bedre en \textit{CUDA}, dette tilfælde kunne skylde at \textit{C++ AMP} måske har en smule optimering af data til tråde, fordi i \textit{C++ AMP} skal der ikke findes ud af hvor mange tråde og blokke der skal bruges til at køre en funktion, men i sted giver man et \textit{array} man vil havde gået igennem på GPU. hvorimod i \textit{CUDA} skal man selv programmerer, hvor mange tråde og blokke der skal bruges. En anden årsag til at \textit{CUDA} havde dårlige målinger, vil være dårlig optimeret kode.

En overraskende ting kan observeres i \textit{CUDAfy} 1d og 2d kan noteteres, at det er hurtigere, hvis håndterede data i 1d \textit{array} i sted for 2d \textit{array}, når matrixen begynder at blive størrelse på 10 eller over. Hvilket er det modsatte af hvad artiklen \textit{Adaptive Input-aware Compilation for Graphics Engines}\cite{samadi2012adaptive} beskriver.

Det største problem jeg har haft med med \textit{CUDA} og \textit{CUDAfy} er, at man selv skal finde ud af, hvor mange blokke og antal tråde pr. blok man skal bruge. Hvilket godt kan give nogen problemer, når man arbejder med et program, der skal arbejde med varierende input. Efter hvad jeg har fundet på nettet angående problem med hvor mange blokke og antal tråde pr. blok man skal bruge, har jeg for det meste fundet, at man skal teste sig frem alt efter, hvad der virker godt på det hardware man tester på. Noget man også kunne kigge på er om artiklen \textit{Adaptive Input-aware Compilation for Graphics Engines}\cite{samadi2012adaptive} kunne bruges til at øge hvor effektiv GPU funktion er. For at løse problemet med varierede tråde mænge, har jeg fremstillet en generist metode, der finder ud af, hvor mange blokke der skal bruges, ved at hente information om GPU igennem funktioner som \textit{CUDA} og \textit{CUDAfy} stiller til rådighed. Denne information indeholder eksempelvis hvor mange tråde der maksimal kan være i en block på GPU. Hvor ved hvis en enkel block ikke kan holde det antal af tråde der skal bruges, vil denne metode finde antallet af blokke, der er nødvendig for at kunne holde den mængden af tråde der skal bruges i udregningen. Denne metode er dog ikke perfekt, siden der kunne laves noget optimering af hvordan data bliver gemt til GPU. 

Igennem resultaterne af testene der kan ses i afsnit \ref{result_GPU_Funcalc} for GPU funktion og den simple måde at lave funktioner til \textit{Corecalc}, det kan ses fra testene at jo mere der skal udregnes jo bedre er det at gøre det på GPU, i stedet for at gøre det på den normal måde. Det kan ses på figure \ref{fig:Test_size} at størrelsen af data ikke har den store indflydelse på om GPU bliver bedre at bruge. Dog kan det ses ud fra testene der er figure \ref{fig:Funcalc_test_2} og \ref{fig:Funcalc_test_1}, GPU næsten er en vandret linje, hvorimod at den metoden at stille denne form for udregningen op, bliver til en linje med en stigning på cirka 45\%. Derfor ville funktion, hvor man skal genbruge data meget, såsom matrix multiplikation virke effektiv på en GPU. Noget anden der kan tages fra testen med varierende størrelser af data mængde er, at igennem \textit{Corecalc and Funcalc} er det ikke muligt at ramme for hvad GPU maksimal kan holde af data i et ark. Men da test af matrix multiplikation gav fejlen med ikke mere fri data på GPU, skal man tænke over at 3 \textit{array} på størrelse på over 1023 x 1023 bliver allokeret på GPU og igennem \textit{Corecalc and Funcalc} ark er det kun muligt af lave et \textit{array} på 1000 x 19, siden det sidste kolonne skal bruges på at holde udregningen. Så ud fra testen ser man at, hvis udtrykket er stort, kan det betale sig at flytte udregningen over på GPU. En løsningen på dette problem, hvis det skulle opstå, kunne være, at begynde på brug af billede hukommelse på GPU'en til readonly data. Hvilke skulle være muligt med \textit{CUDA}, men desværre ikke skulle være muligt med \textit{CUDAfy} på dette tidspunkt. 